# -*- coding: utf-8 -*-
"""Untitled23.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1umzxWFdnYyfUnx-VHK87APeGKVtCLPv1
"""

!pip install paddlepaddle -i https://mirror.baidu.com/pypi/simple

!pip install faiss-cpu

# Install paddleocr, version 2.6 is recommended
!pip install "paddleocr>=2.6.0.3"

# Install the image direction classification dependency package paddleclas (if you do not use the image direction classification, you can skip it)

!git clone https://github.com/PaddlePaddle/PaddleOCR

!paddleocr --image_dir='/content/PaddleOCR/ppstructure/docs/table/1.png' --type=structure

!wget https://paddleocr.bj.bcebos.com/whl/layoutparser-0.0.0-py3-none-any.whl
!pip install -U layoutparser-0.0.0-py3-none-any.whl

import os
import cv2
import layoutparser as lp
image = cv2.imread("/content/invoice-template-classic_invoice (1).png")

image = image[..., ::-1]

# load model
model = lp.PaddleDetectionLayoutModel(config_path="lp://PubLayNet/ppyolov2_r50vd_dcn_365e_publaynet/config",
                                threshold=0.5,
                                label_map={0: "Text", 1: "Title", 2: "List", 3:"Table", 4:"Figure"},
                                enforce_cpu=False,
                                enable_mkldnn=True)#math kernel library
# detect
layout = model.detect(image)

import os
import cv2
from paddleocr import PPStructure,draw_structure_result,save_structure_res

table_engine = PPStructure(show_log=True)

save_folder = './output'
img_path = '/content/invoice-template-classic_invoice (1).png'
img = cv2.imread(img_path)
result = table_engine(img)
save_structure_res(result, save_folder,os.path.basename(img_path).split('.')[0])

for line in result:
    line.pop('img')
    print(line)

from PIL import Image

font_path = os.path.join('PaddleOCR', 'doc', 'fonts', 'latin.ttf')
image = Image.open(img_path).convert('RGB')
im_show = draw_structure_result(image, result,font_path=font_path)
im_show = Image.fromarray(im_show)
im_show.save('result.jpg')

im_show

table_coordinates = []
text_coordinates = []
figure_coordinates = []
list_coordinates =[]
title_coordinates = []
for line in result:
    if line['type'] == 'table':
        table_coordinates.append(line['bbox'])
    if line['type'] == 'text':
        table_coordinates.append(line['bbox'])
    if line['type'] == 'list':
        table_coordinates.append(line['bbox'])
    if line['type'] == 'figure':
        table_coordinates.append(line['bbox'])
    if line['type'] == 'title':
        table_coordinates.append(line['bbox'])

table_coordinates

table1 = table_coordinates[-1]
x1, y1, x2, y2 = table1

im = cv2.imread(img_path)

cv2.imwrite("extracted_image.jpg", im[y1 : y2, x1 : x2])

!git clone https://github.com/PaddlePaddle/PaddleOCR

from paddleocr import PaddleOCR, draw_ocr # main OCR dependencies
from matplotlib import pyplot as plt # plot images
import cv2 #opencv
import os # folder directory navigation

ocr_model = PaddleOCR(lang='en')

font_path = os.path.join('PaddleOCR', 'doc', 'fonts', 'latin.ttf')
img = cv2.imread('/content/extracted_image.jpg')
result = ocr_model.ocr('/content/extracted_image.jpg')
texts=[]
for res in result:
  for i in range(len(res)):
    texts.append(res[i][1][0])
scores=[]
for res in result:
  for i in range(len(res)):
    scores.append(res[i][1][1])
boxes=[]
for res in result:
  for i in range(len(res)):
    boxes.append(res[i][0])
plt.figure(figsize=(100, 100))

  # draw annotations on image
annotated = draw_ocr(img , boxes, texts, scores, font_path=font_path)

  # show the image using matplotlib

plt.imshow(annotated)

image_cv = cv2.imread('/content/extracted_image.jpg')

im = image_cv.copy()

image_height = image_cv.shape[0]
image_width = image_cv.shape[1]

horiz_boxes = []
vert_boxes = []

for box in boxes:
  x_h, x_v = 0,int(box[0][0])
  y_h, y_v = int(box[0][1]),0
  width_h,width_v = image_width, int(box[2][0]-box[0][0])
  height_h,height_v = int(box[2][1]-box[0][1]),image_height

  horiz_boxes.append([x_h,y_h,x_h+width_h,y_h+height_h])
  vert_boxes.append([x_v,y_v,x_v+width_v,y_v+height_v])

  cv2.rectangle(im,(x_h,y_h), (x_h+width_h,y_h+height_h),(0,0,255),1)
  cv2.rectangle(im,(x_v,y_v), (x_v+width_v,y_v+height_v),(0,255,0),1)

cv2.imwrite('horiz_vert.jpg',im)

boxes[0]

horiz_boxes[0]

import tensorflow as tf

horiz_out = tf.image.non_max_suppression(
    horiz_boxes,
    scores,
    max_output_size = 1000,
    iou_threshold=0.1,
    score_threshold=float('-inf'),
    name=None
)

import numpy as np

horiz_lines = np.sort(np.array(horiz_out))
print(horiz_lines)

im_nms = image_cv.copy()

for val in horiz_lines:
  cv2.rectangle(im_nms, (int(horiz_boxes[val][0]),int(horiz_boxes[val][1])), (int(horiz_boxes[val][2]),int(horiz_boxes[val][3])),(0,0,255),1)

cv2.imwrite('im_nms.jpg',im_nms)

vert_out = tf.image.non_max_suppression(
    vert_boxes,
    scores,
    max_output_size = 2000,
    iou_threshold=0.01,
    score_threshold=float('-inf'),
    name=None
)

print(vert_out)

vert_lines = np.sort(np.array(vert_out))
print(vert_lines)

for val in vert_lines:
  cv2.rectangle(im_nms, (int(vert_boxes[val][0]),int(vert_boxes[val][1])), (int(vert_boxes[val][2]),int(vert_boxes[val][3])),(255,0,0),1)

cv2.imwrite('im_nms.jpg',im_nms)

out_array = [["" for i in range(len(vert_lines))] for j in range(len(horiz_lines))]
print(np.array(out_array).shape)
print(out_array)

unordered_boxes = []

for i in vert_lines:
  print(vert_boxes[i])
  unordered_boxes.append(vert_boxes[i][0])

ordered_boxes = np.argsort(unordered_boxes)
print(ordered_boxes)

def intersection(box_1, box_2):
  return [box_2[0], box_1[1],box_2[2], box_1[3]]

def iou(box_1, box_2):

  x_1 = max(box_1[0], box_2[0])
  y_1 = max(box_1[1], box_2[1])
  x_2 = min(box_1[2], box_2[2])
  y_2 = min(box_1[3], box_2[3])

  inter = abs(max((x_2 - x_1, 0)) * max((y_2 - y_1), 0))
  if inter == 0:
      return 0

  box_1_area = abs((box_1[2] - box_1[0]) * (box_1[3] - box_1[1]))
  box_2_area = abs((box_2[2] - box_2[0]) * (box_2[3] - box_2[1]))

  return inter / float(box_1_area + box_2_area - inter)

for i in range(len(horiz_lines)):
  for j in range(len(vert_lines)):
    resultant = intersection(horiz_boxes[horiz_lines[i]], vert_boxes[vert_lines[ordered_boxes[j]]] )

    for b in range(len(boxes)):
      the_box = [boxes[b][0][0],boxes[b][0][1],boxes[b][2][0],boxes[b][2][1]]
      if(iou(resultant,the_box)>0.1):
        out_array[i][j] = texts[b]

out_array=np.array(out_array)

out_array

import pandas as pd

pd.DataFrame(out_array).to_csv('sample.csv')

pd.read_csv("/content/sample.csv")